{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laurels and Crowns: Ancient Roman Coins Classification Using Computer Vision\n",
        "\n",
        "Val√©rie BLANCH\n",
        "\n",
        "2614867B@student.gla.ac.uk\n",
        "\n",
        "University of Glasgow\n",
        "\n",
        "September 2022\n"
      ],
      "metadata": {
        "id": "MxkL_CVAAANO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKHOt9yAfpOO"
      },
      "source": [
        "# Link to the dataset\n",
        "The .zip file contains the text data, the images and the saved weigths of the trained models described in the dissertation.\n",
        "\n",
        "https://drive.google.com/file/d/1y-hHm1IWHguGPKzfZi6Q4_84LLcUvktv/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HZID-FwBCRN"
      },
      "outputs": [],
      "source": [
        "pip install tf-explain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69N0uPrLhvEe"
      },
      "outputs": [],
      "source": [
        "#importing modules\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import Model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import random \n",
        "from tf_explain.core.grad_cam import GradCAM\n",
        "import cv2\n",
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOV8jON3c3Jv"
      },
      "outputs": [],
      "source": [
        "#extracting the zip file\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/coins2.zip', 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()\n",
        "\n",
        "#setting the paths of the training, validation & test sets\n",
        "\n",
        "base_dir = 'tmp/coins2'\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_denarius_dir = os.path.join(train_dir, 'denarius') \n",
        "train_antoninianus_dir = os.path.join(train_dir, 'antoninianus') \n",
        "\n",
        "validation_denarius_dir = os.path.join(validation_dir, 'denarius')\n",
        "validation_antoninianus_dir = os.path.join(validation_dir, 'antoninianus') \n",
        " \n",
        "test_denarius_dir = os.path.join(test_dir, 'denarius') \n",
        "test_antoninianus_dir = os.path.join(test_dir, 'antoninianus')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1oOXvVvr984"
      },
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1qh-ekWsOaI"
      },
      "outputs": [],
      "source": [
        "#loading the datasets\n",
        "\n",
        "antoninianus = pd.read_csv('tmp/coins2/antoninianus.csv')\n",
        "denarius = pd.read_csv('tmp/coins2/denarius.csv')\n",
        "\n",
        "#printing several rows of the antoninianus dataframe & dimensions\n",
        "\n",
        "antoninianus.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XaqGuaQSQZI"
      },
      "outputs": [],
      "source": [
        "#printing the dimensions of the antoninianus dataframe\n",
        "\n",
        "antoninianus.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp_OLLslSEXa"
      },
      "outputs": [],
      "source": [
        "#printing the dimensions of the denarius dataframe\n",
        "\n",
        "denarius.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsrlw5mVxMZp"
      },
      "outputs": [],
      "source": [
        "#printing several rows of the denarius dataframe\n",
        "\n",
        "denarius.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tjzZSSusatJ"
      },
      "outputs": [],
      "source": [
        "#inspecting missing values in the relevant variables\n",
        "\n",
        "print(antoninianus['Coin'].isna().sum())\n",
        "print(denarius['Coin'].isna().sum())\n",
        "print(antoninianus['Obverse_URL'].isna().sum())\n",
        "print(denarius['Obverse_URL'].isna().sum())\n",
        "print(antoninianus['Denomination'].isna().sum())\n",
        "print(denarius['Denomination'].isna().sum())\n",
        "print(antoninianus['Obverse_Description'].isna().sum())\n",
        "print(denarius['Obverse_Description'].isna().sum())\n",
        "\n",
        "#inspecting duplicates\n",
        "\n",
        "print(antoninianus['Coin'].nunique())\n",
        "print(denarius['Coin'].nunique())\n",
        "\n",
        "#inspecting denominations\n",
        "\n",
        "print(antoninianus['Denomination'].unique())\n",
        "print(denarius['Denomination'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hAFB2qyt2sW"
      },
      "outputs": [],
      "source": [
        "#computing an average date from estimated range\n",
        "\n",
        "antoninianus['Year'] = (antoninianus['From_Date'] + antoninianus['To_Date'])/2\n",
        "denarius['Year'] = (denarius['From_Date'] + denarius['To_Date'])/2\n",
        "\n",
        "#plotting dates for antoniniani\n",
        "\n",
        "antoninianus.groupby('Year')['Coin'].nunique().plot()\n",
        "plt.title('Number of antoniniani found per year of production')\n",
        "plt.xlabel('Estimated year of production')\n",
        "plt.ylabel('Number of coins found');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz_k5ANd5dlm"
      },
      "outputs": [],
      "source": [
        "#plotting dates for denarii\n",
        "\n",
        "denarius.groupby('Year')['Coin'].nunique().plot()\n",
        "plt.title('Number of denarii found per year of production')\n",
        "plt.xlabel('Estimated year of production')\n",
        "plt.ylabel('Number of coins found');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbl1Oicci3K2"
      },
      "outputs": [],
      "source": [
        "#printing number of radiate portraits for antoniniani\n",
        "\n",
        "print(antoninianus.Obverse_Description.str.contains('radiate').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTC6R3xihcl8"
      },
      "outputs": [],
      "source": [
        "#printing number of hairtsyles for antoniniani that are not radiate crowns\n",
        "\n",
        "anton_divergent = antoninianus[~antoninianus['Obverse_Description'].str.contains('radiate',\n",
        "                                                                    na=False)]\n",
        "anton_divergent.shape                                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf_2RQJgpndQ"
      },
      "outputs": [],
      "source": [
        "anton_divergent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikIifCGWkycm"
      },
      "outputs": [],
      "source": [
        "#displaying hairstyles for antoniniani that are not radiate crowns\n",
        "\n",
        "for i in range(0,5):\n",
        "  display(Image(anton_divergent.iloc[i,6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEB_ArRmq_ZF"
      },
      "outputs": [],
      "source": [
        "#drawing a plot for the proportion of hairstyles for antoniniani\n",
        "\n",
        "y = [antoninianus.Obverse_Description.str.contains('radiate').sum()+5, 0]\n",
        "x = ['Radiate', 'Other']\n",
        "\n",
        "plt.bar(x, y)\n",
        "plt.title('Type of Hairstyles for Antoniniani')\n",
        "plt.xlabel('Type of hairstyles')\n",
        "plt.ylabel('Occurrences');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd9rASJhrYRM"
      },
      "outputs": [],
      "source": [
        "#printing occurrences of hairstyles for denarii\n",
        "\n",
        "print(denarius.Obverse_Description.str.contains('radiate').sum())\n",
        "print(denarius.Obverse_Description.str.contains('laureate').sum())\n",
        "print(denarius.Obverse_Description.str.contains('bare').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awOB9xMLrlXt"
      },
      "outputs": [],
      "source": [
        "#inspecting radiate crowns in denarius dataset\n",
        "\n",
        "radiate = denarius[denarius['Obverse_Description'].str.contains('radiate',\n",
        "                                                                    na=False)]\n",
        "radiate.shape      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwsSoyW5tOvd"
      },
      "outputs": [],
      "source": [
        "radiate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JKdCJ0gr0z1"
      },
      "outputs": [],
      "source": [
        "#displaying radiate crowns in denarius dataset\n",
        "\n",
        "for i in range(0,2):\n",
        "  display(Image(radiate.iloc[i,6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJv7KCMbOu8v"
      },
      "outputs": [],
      "source": [
        "y = [2, 9568, 1811, 134]\n",
        "x = ['Radiate', 'Laureate', 'Bareheaded', 'Other']\n",
        "\n",
        "plt.bar(x, y)\n",
        "plt.title('Type of Hairstyles for Denarii')\n",
        "plt.xlabel('Type of hairstyles')\n",
        "plt.ylabel('Occurrences');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmJGu76FcmOA"
      },
      "outputs": [],
      "source": [
        "#computing the summary statistics of diameter and weight\n",
        "\n",
        "print(antoninianus['Diameter'].describe())\n",
        "print(antoninianus['Weight'].describe())\n",
        "print(denarius['Diameter'].describe())\n",
        "print(denarius['Weight'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSbyDssbcSQ1"
      },
      "source": [
        "# Image Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9YDd9MvWrjl"
      },
      "outputs": [],
      "source": [
        "#displaying several coins of the two denominations\n",
        "\n",
        "train_antoninianus_fnames = os.listdir( train_antoninianus_dir )\n",
        "train_denarius_fnames = os.listdir( train_denarius_dir )\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0 \n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "next_antoninianus_pix = [os.path.join(train_antoninianus_dir, fname) \n",
        "                for fname in train_antoninianus_fnames[ pic_index-8:pic_index] \n",
        "               ]\n",
        "\n",
        "next_denarius_pix = [os.path.join(train_denarius_dir, fname) \n",
        "                for fname in train_denarius_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "for i, img_path in enumerate(next_antoninianus_pix+next_denarius_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') \n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI1pFMunlP2N"
      },
      "outputs": [],
      "source": [
        "#averaging the images from the train set - antoninianius\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "antoninianus_pix = [os.path.join(train_antoninianus_dir, fname) \n",
        "                for fname in train_antoninianus_fnames \n",
        "               ]\n",
        "\n",
        "img=[]\n",
        "\n",
        "for i in antoninianus_pix:\n",
        "\n",
        "  image = load_img(i)\n",
        "  image = img_to_array(image)\n",
        "  img.append(image)\n",
        "\n",
        "img = np.array(img)\n",
        "avg = np.average(img,axis=0)\n",
        "train_anton = Image.fromarray(avg.astype('uint8'))\n",
        "plt.imshow(train_anton)\n",
        "plt.axis('Off') \n",
        "plt.title('Average image from training set - antoninianus');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgq_4KorGO8q"
      },
      "outputs": [],
      "source": [
        "#averaging images from the train set - denarius\n",
        "\n",
        "denarius_pix = [os.path.join(train_denarius_dir, fname) \n",
        "                for fname in train_denarius_fnames \n",
        "               ]\n",
        "\n",
        "img=[]\n",
        "\n",
        "for i in denarius_pix:\n",
        "\n",
        "  image = load_img(i)\n",
        "  image = img_to_array(image)\n",
        "  img.append(image)\n",
        "\n",
        "img = np.array(img)\n",
        "avg = np.average(img,axis=0)\n",
        "train_den = Image.fromarray(avg.astype('uint8'))\n",
        "plt.imshow(train_den)\n",
        "plt.axis('Off') \n",
        "plt.title('Average image from training set - denarius');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHAs_8Pjf-9q"
      },
      "source": [
        "# Model 1 :  CNN with grayscale images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84KFjK-W9qRi"
      },
      "outputs": [],
      "source": [
        "#preprocessing the data : rescaling, augmentation with rotation & mirroring\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK5UjtBYhGQe"
      },
      "outputs": [],
      "source": [
        "#generating batches of 100 for training & validation sets in grayscale\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 100,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    target_size = (150, 150),\n",
        "                                                    classes={'denarius': 0, \n",
        "                                                          'antoninianus': 1})     \n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size = 100,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                        color_mode='grayscale',\n",
        "                                                       classes={'denarius': 0, \n",
        "                                                          'antoninianus': 1},\n",
        "                                                      target_size = (150, 150))\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale',\n",
        "        classes={'denarius': 0, \n",
        "        'antoninianus': 1},\n",
        "        shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzH4HQQTQObC"
      },
      "outputs": [],
      "source": [
        "#verifying the indices of the categories\n",
        "\n",
        "print(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXS-dM0UlEFO"
      },
      "outputs": [],
      "source": [
        "#defining the layers of the model\n",
        "\n",
        "model_1 = tf.keras.models.Sequential([                                                      \n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "#printing the summary of the model\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds27mM2DlRTh"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_1.compile(optimizer = 'rmsprop', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfDaUPq6xQ1G"
      },
      "outputs": [],
      "source": [
        "#defining a checkpoint to save the best model during training\n",
        "\n",
        "checkpoint_path = 'tmp/model_1_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nxOvYe6lX5E"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_1 = model_1.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk6UtTQNlb32"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 1')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "plt.title('Loss - Model 1')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V7YiC02ENIX"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_1.load_weights(checkpoint_path)\n",
        "model_1.evaluate(validation_generator)\n",
        "\n",
        "#or loading the weights used in the dissertation\n",
        "\n",
        "#model_1.load_weights('tmp/coins2/model_1.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYC7sP37lhWS"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "probabilities = model_1.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_1.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "pmRWg6uL2nhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tceOfY40f-nZ"
      },
      "source": [
        "# Model 2 : Updated CNN with grayscale images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpNrSGFihIKW"
      },
      "outputs": [],
      "source": [
        "#defining the layers of the model\n",
        "\n",
        "model_2 = tf.keras.models.Sequential([                                                      \n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "#printing the summary of the model\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwLpl9-phSeu"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_2.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFjmjOj0E0tf"
      },
      "outputs": [],
      "source": [
        "#creating a checkpoint callback to save the best model\n",
        "\n",
        "checkpoint_path = 'tmp/model_2_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2zfDrDKhf98"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jp0uzTuhmWa"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 2')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.title('Loss - Model 2')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N9rffZwE0tk"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_2.load_weights(checkpoint_path)\n",
        "model_2.evaluate(validation_generator)\n",
        "\n",
        "#or loading the weights used for the dissertation\n",
        "\n",
        "#model_2.load_weights('tmp/coins2/model_2.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmFYDYkmhuIB"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "probabilities = model_2.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_2.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "pw3eqigy13Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnun5cEBUbgU"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uz3SkwgUbgV"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpURPpyrUbgW"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBM-DCFUUbgX"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150), \n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_6')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-easAKFUUbgY"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150), \n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=0, layer_name='conv2d_6')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying gradCAM of true antoniniani (first layer)\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_3')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ],
      "metadata": {
        "id": "jxajXR4y87_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying gradCAM of true antoniniani (second layer)\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_4')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ],
      "metadata": {
        "id": "JjlyYzZ187oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying gradCAM of true antoniniani (third layer)\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_5')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ],
      "metadata": {
        "id": "HGzwvO0_87VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzZPp3miUbgZ"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani (fourth layer)\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_6')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLzocIbDUbga"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true denarii\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=0, layer_name='conv2d_6')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUWf27SIgO-_"
      },
      "source": [
        "# Model 3 : CNN with RGB images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_JplJmTBr59"
      },
      "outputs": [],
      "source": [
        "#new generator objects with RGB images\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 100,\n",
        "                                                    target_size = (150, 150),\n",
        "                                                   class_mode='categorical',\n",
        "                                                    classes={'denarius': 0, \n",
        "                                                          'antoninianus': 1})     \n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size = 100,\n",
        "                                                      target_size = (150, 150),\n",
        "                                                       class_mode='categorical',\n",
        "                                                       classes={'denarius': 0, \n",
        "                                                          'antoninianus': 1})\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        shuffle=False,\n",
        "       class_mode='categorical',\n",
        "        classes={'denarius': 0, \n",
        "                'antoninianus': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7hTxbAs691x"
      },
      "outputs": [],
      "source": [
        "#creating the cnn\n",
        "\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "#printing Print the model summary\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hsHo_9g69SV"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_3.compile(optimizer = 'rmsprop', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vS4AQ0LE_4y"
      },
      "outputs": [],
      "source": [
        "#creating a checkpoint callback to save the best model\n",
        "\n",
        "checkpoint_path = 'tmp/model_3_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGBIzTAG7Nd7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_3 = model_3.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9v0Rljy7Nd8"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_3.history['accuracy'])\n",
        "plt.plot(history_3.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 3')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_3.history['loss'])\n",
        "plt.plot(history_3.history['val_loss'])\n",
        "plt.title('Loss - Model 3')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU7TW6QNE_4z"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_3.load_weights(checkpoint_path)\n",
        "model_3.evaluate(validation_generator)\n",
        "\n",
        "#or loading the weights used for the dissertation\n",
        "\n",
        "#model_3.load_weights('tmp/coins2/model_3.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hZ8hR3F7Nd9"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_3.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 3')\n",
        "\n",
        "print(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_3.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "BwK18wVs2Vy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md-VSye65jBF"
      },
      "source": [
        "# Model 4 : Updated CNN with RGB images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8BPlUNN2dC_"
      },
      "outputs": [],
      "source": [
        "#creating the cnn\n",
        "\n",
        "model_4 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "#printing Print the model summary\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE597ZB_2eKP"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_4.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F9Q4ej1FHUq"
      },
      "outputs": [],
      "source": [
        "#creating a checkpoint callback to save the best model\n",
        "\n",
        "checkpoint_path = 'tmp/model_4_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq8rcVL3-Mif"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_4 = model_4.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jiMWKuq8x-C"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_4.history['accuracy'])\n",
        "plt.plot(history_4.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 4')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_4.history['loss'])\n",
        "plt.plot(history_4.history['val_loss'])\n",
        "plt.title('Loss - Model 4')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZgRWe2GFHUt"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_4.load_weights(checkpoint_path)\n",
        "model_4.evaluate(validation_generator)\n",
        "\n",
        "#or loading the weights used for the dissertation\n",
        "\n",
        "#model_4.load_weights('tmp/coins2/model_4.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPC_8HrS9sTi"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_4.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 4')\n",
        "\n",
        "print(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_4.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "GtKxd2Ld2Mh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjyIWoSuepyL"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_PIuZRrNNhM"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Bzg1TSYn5r"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv4j8B7bgdUN"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=1, layer_name='conv2d_16')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvLcmkelgdUL"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=0, layer_name='conv2d_16')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPZk_eK5gdUM"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150, 3))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=1, layer_name='conv2d_16')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kECdHG_-gdUO"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true denarii\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=0, layer_name='conv2d_16')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Qyx6T-gvNP"
      },
      "source": [
        "# Model 5 : Transfert Learning with Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji_rbxqhb-UV"
      },
      "outputs": [],
      "source": [
        "#downloading inceptionv3 without the final layers\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "#saving it into a variable\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "#setting the input shape\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "#loading the weights\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "#freezing the layers of the model\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFnc4-n1utlH"
      },
      "outputs": [],
      "source": [
        "#printing the layers of the pretrained model\n",
        "\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSuuNqscu5Ys"
      },
      "outputs": [],
      "source": [
        "#only using the model up to the 7th module\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knyOkAqgvGnK"
      },
      "outputs": [],
      "source": [
        "#adding layers to the pretrained model\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense(2, activation='softmax')(x)           \n",
        "\n",
        "model_5 = Model(pre_trained_model.input, x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCR_F2R3vrJE"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_5.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#printing the model summary \n",
        "\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asBgR2pXFRAG"
      },
      "outputs": [],
      "source": [
        "#creating a checkpoint callback to save the best model\n",
        "\n",
        "checkpoint_path = 'tmp/model_5_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7x_TCYrvxxE"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_5 = model_5.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3KFAKHkwHKW"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_5.history['accuracy'])\n",
        "plt.plot(history_5.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 5')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_5.history['loss'])\n",
        "plt.plot(history_5.history['val_loss'])\n",
        "plt.title('Loss - Model 5')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZr5FBflFRAL"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_5.load_weights(checkpoint_path)\n",
        "model_5.evaluate(validation_generator)\n",
        "\n",
        "#or loading weights used for dissertation\n",
        "\n",
        "#model_5.load_weights('tmp/coins2/model_5.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7xcNhDpTfoj"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_5.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 5')\n",
        "plt.show()\n",
        "\n",
        "print(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_5.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "YzkNhou92bER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1qwh08WAcmD"
      },
      "source": [
        "# Model 6 : Updated InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oof9nfSpc5Zc"
      },
      "outputs": [],
      "source": [
        "#only using the model up to the 4th module\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed4')\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj6mdJ42c84P"
      },
      "outputs": [],
      "source": [
        "#adding layers to the pre-trained model\n",
        "\n",
        "x = layers.Conv2D(128, (3,3), activation='relu')(last_output)\n",
        "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x) \n",
        "x = layers.Dense(2, activation='softmax')(x)           \n",
        "\n",
        "#building the model\n",
        "\n",
        "model_6 = Model(pre_trained_model.input, x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRGSUZHAc-2p"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "\n",
        "model_6.compile(optimizer = 'adam', \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#printing the summary of the model\n",
        "\n",
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7u-WIenFZe5"
      },
      "outputs": [],
      "source": [
        "#creating a checkpoint callback to save the best model\n",
        "\n",
        "checkpoint_path = 'tmp/model_6_new.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True, \n",
        "                                                verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO2TtEGrdBFA"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#training the model\n",
        "\n",
        "history_6 = model_6.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 140,\n",
        "            epochs = 50,\n",
        "            validation_steps = 70,\n",
        "            callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73Dh0wSsdJ32"
      },
      "outputs": [],
      "source": [
        "#plotting the accuracy for training & validation sets\n",
        "\n",
        "plt.plot(history_6.history['accuracy'])\n",
        "plt.plot(history_6.history['val_accuracy'])\n",
        "plt.title('Accuracy - Model 6')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "#plotting the loss for training & validation sets\n",
        "\n",
        "plt.plot(history_6.history['loss'])\n",
        "plt.plot(history_6.history['val_loss'])\n",
        "plt.title('Loss - Model 6')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlI9gA_5FZfF"
      },
      "outputs": [],
      "source": [
        "#updating the model with best weights\n",
        "\n",
        "model_6.load_weights(checkpoint_path)\n",
        "model_6.evaluate(validation_generator)\n",
        "\n",
        "#or loading weights used for the dissertation\n",
        "\n",
        "#model_6.load_weights('tmp/coins2/model_6.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfVyKhlH4Zqz"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_6.predict(test_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_generator.classes, y_pred, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Model 6')\n",
        "plt.show()\n",
        "\n",
        "print(test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy on the test set\n",
        "\n",
        "model_6.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "MFYIL1HD2g83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtFH9V2d4eTZ"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNT6-Np2nC0q"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9B-7PxsoorT"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Yi2uLAWAB1g"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPGrXC5PRVCp"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=1, layer_name='conv2d_111')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1__pMBh9N3EU"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=1, layer_name='conv2d_111')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYKueVLjQuM5"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true denarii\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN7YqCZf7R_T"
      },
      "outputs": [],
      "source": [
        "#testing the two denarius with radiate crowns\n",
        "\n",
        "path = 'tmp/coins2/validation/denarius/den_9480.jpg'\n",
        "img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150,3))\n",
        "img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "img /= 255\n",
        "img = ([img], None)\n",
        "\n",
        "explainer = GradCAM()\n",
        "grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "grid = Image.fromarray(grid)\n",
        "plt.axis('Off')\n",
        "plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69usX-gD7mLs"
      },
      "outputs": [],
      "source": [
        "#testing the two denarius with radiate crowns\n",
        "\n",
        "path = 'tmp/coins2/validation/denarius/den_11240.jpg'\n",
        "img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150,3))\n",
        "img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "img /= 255\n",
        "img = ([img], None)\n",
        "\n",
        "explainer = GradCAM()\n",
        "grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "grid = Image.fromarray(grid)\n",
        "plt.axis('Off')\n",
        "plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElLpMSWcgLcx"
      },
      "source": [
        "# New Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPmXs3yBSjJu"
      },
      "outputs": [],
      "source": [
        "#drawing a stacked bar plot of the distribution of collections per denomination\n",
        "\n",
        "anton_coll = pd.DataFrame(antoninianus['Collection_URI'].value_counts()).reset_index()\n",
        "den_coll = pd.DataFrame(denarius['Collection_URI'].value_counts()).reset_index()\n",
        "\n",
        "#renaming columns\n",
        "\n",
        "anton_coll = anton_coll.rename(columns={'index': 'Collection_URI', 'Collection_URI': 'antoninianus'})\n",
        "den_coll = den_coll.rename(columns={'index': 'Collection_URI', 'Collection_URI': 'denarius'})\n",
        "\n",
        "#merging dataframes\n",
        "\n",
        "collections = pd.merge(den_coll, anton_coll, how='left')\n",
        "\n",
        "#transposing the dataframe\n",
        "\n",
        "collections = pd.DataFrame.transpose(collections)\n",
        "collections = (collections.rename(columns=collections.iloc[0])).drop(collections.index[0])\n",
        "\n",
        "#drawing the plot\n",
        "\n",
        "plot = collections.plot.bar(stacked=True, rot=0)\n",
        "plot.set_title('Distribution of coins per type and collection')\n",
        "plot.legend(loc='center left',bbox_to_anchor=(1.0, 0.5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOcJp8HMh97x"
      },
      "outputs": [],
      "source": [
        "#loading the new test set\n",
        "\n",
        "test2_dir = os.path.join(base_dir, 'test2')\n",
        "\n",
        "test2_denarius_dir = os.path.join(test2_dir, 'denarius') \n",
        "test2_antoninianus_dir = os.path.join(test2_dir, 'antoninianus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq1Xa5RciA6w"
      },
      "outputs": [],
      "source": [
        "#displaying several coins\n",
        "\n",
        "test2_antoninianus_fnames = os.listdir(test2_antoninianus_dir)\n",
        "test2_denarius_fnames = os.listdir(test2_denarius_dir)\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0 \n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "next_antoninianus_pix = [os.path.join(test2_antoninianus_dir, fname) \n",
        "                for fname in test2_antoninianus_fnames[ pic_index-8:pic_index] \n",
        "               ]\n",
        "\n",
        "next_denarius_pix = [os.path.join(test2_denarius_dir, fname) \n",
        "                for fname in test2_denarius_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "for i, img_path in enumerate(next_antoninianus_pix+next_denarius_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') \n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boXc3hJ32A5S"
      },
      "outputs": [],
      "source": [
        "#averaging the images from the second test set - antoninianius\n",
        "\n",
        "antoninianus_pix = [os.path.join(test2_antoninianus_dir, fname) \n",
        "                for fname in test2_antoninianus_fnames \n",
        "               ]\n",
        "\n",
        "img=[]\n",
        "\n",
        "for i in antoninianus_pix:\n",
        "\n",
        "  image = load_img(i)\n",
        "  image = img_to_array(image)\n",
        "  img.append(image)\n",
        "\n",
        "img = np.array(img)\n",
        "avg = np.average(img,axis=0)\n",
        "test2_anton = Image.fromarray(avg.astype('uint8'))\n",
        "plt.imshow(test2_anton)\n",
        "plt.axis('Off') \n",
        "plt.title('Average image from second test set - antoninianus');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFwbEDMH2A5X"
      },
      "outputs": [],
      "source": [
        "#averaging images from the second test set - denarius\n",
        "\n",
        "denarius_pix = [os.path.join(test2_denarius_dir, fname) \n",
        "                for fname in test2_denarius_fnames \n",
        "               ]\n",
        "\n",
        "img=[]\n",
        "\n",
        "for i in denarius_pix:\n",
        "\n",
        "  image = load_img(i)\n",
        "  image = img_to_array(image)\n",
        "  img.append(image)\n",
        "\n",
        "img = np.array(img)\n",
        "avg = np.average(img,axis=0)\n",
        "test2_den = Image.fromarray(avg.astype('uint8'))\n",
        "plt.imshow(test2_den)\n",
        "plt.axis('Off') \n",
        "plt.title('Average image from second test set - denarius');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 - Second Test"
      ],
      "metadata": {
        "id": "KZGtd3G1IGv_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USeXvtsrmFmC"
      },
      "outputs": [],
      "source": [
        "#preprocessing the data\n",
        "\n",
        "test2_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "test2_generator = test2_datagen.flow_from_directory(\n",
        "        test2_dir,\n",
        "        target_size=(150, 150),\n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale',\n",
        "        classes={'denarius': 0, \n",
        "        'antoninianus': 1},\n",
        "        shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_1.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 1 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ],
      "metadata": {
        "id": "IBgZcBTUII0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing accuracy of the second test\n",
        "\n",
        "model_1.evaluate(test2_generator)"
      ],
      "metadata": {
        "id": "so05SpOpIkTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9CMGHvIbBTd"
      },
      "source": [
        "## Model 2 - Second Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf74sDSuojq8"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_2.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 2 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWILsCupP50d"
      },
      "outputs": [],
      "source": [
        "#printing accuracy of the second test\n",
        "\n",
        "model_2.evaluate(test2_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1yFPTM8U1E4"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test2_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test2_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s5S2ChkU1E6"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-IbLPDgU1E7"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJvguFfoU1E8"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test2/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150), \n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_6')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1X01T1FU1E9"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test2/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150), \n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=0, layer_name='conv2d_6')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLVoSbXNU1E-"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=1, layer_name='conv2d_6')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRLxThHIU1E_"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true denarii\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150),\n",
        "                                            color_mode='grayscale')\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_2, class_index=0, layer_name='conv2d_6')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JLMkRtUKEwv"
      },
      "source": [
        "## Model 3 - Second Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMfCOOFMmdZh"
      },
      "outputs": [],
      "source": [
        "#new generator objects with RGB images\n",
        "\n",
        "test2_generator = test2_datagen.flow_from_directory(\n",
        "        test2_dir,\n",
        "        target_size=(150, 150),\n",
        "        shuffle=False,\n",
        "       class_mode='categorical',\n",
        "        classes={'denarius': 0, \n",
        "                'antoninianus': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1SovgtjKEwx"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_3.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 3 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfbJTsFPKEw0"
      },
      "outputs": [],
      "source": [
        "#printing the accuracy of the second test\n",
        "\n",
        "model_3.evaluate(test2_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4sqKwpbKhs"
      },
      "source": [
        "## Model 4 - Second Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-vkvQosowpv"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_4.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 4 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgT4jktMQ9OE"
      },
      "outputs": [],
      "source": [
        "#printing the accuracy of the second test\n",
        "\n",
        "model_4.evaluate(test2_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fIOYPEibsGO"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test2_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test2_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC4BQbBubsGP"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qknfk4QcbsGQ"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjvmQEsAbsGR"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test2/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=1, layer_name='conv2d_16')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOi0Oz6SbsGS"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test2/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=0, layer_name='conv2d_16')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-MdjrNVbsGT"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150, 3))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=1, layer_name='conv2d_16')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsQqL-u9bsGU"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true denarii\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_4, class_index=0, layer_name='conv2d_16')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x-NxzCXLWL3"
      },
      "source": [
        "## Model 5 - Second Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-egQuviLWL5"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_5.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 5 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoiiyv54LWL7"
      },
      "outputs": [],
      "source": [
        "#printing the accuracy of the second test \n",
        "\n",
        "model_5.evaluate(test2_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbuyE14UdOVc"
      },
      "source": [
        "## Model 6 - Second Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaGdKquAo3n5"
      },
      "outputs": [],
      "source": [
        "#making predictions\n",
        "\n",
        "probabilities = model_6.predict(test2_generator)\n",
        "\n",
        "#computing a confusion matrix\n",
        "\n",
        "y_pred = np.argmax(probabilities, axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test2_generator.classes, y_pred, cmap='Oranges')\n",
        "plt.title('Confusion Matrix - Model 6 - Second Test')\n",
        "plt.show()\n",
        "\n",
        "print(test2_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqn-EE7eRWRN"
      },
      "outputs": [],
      "source": [
        "#printing the accuracy of the second test \n",
        "\n",
        "model_6.evaluate(test2_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evKXMWZ5dupG"
      },
      "outputs": [],
      "source": [
        "#creating a dataframe with predictions and filenames\n",
        "\n",
        "pred_df =  pd.DataFrame(y_pred, test2_generator.filenames).reset_index()\n",
        "pred_df = pred_df.rename(columns={'index': 'filenames', 0: 'predictions'})\n",
        "pred_df['classes'] = test2_generator.classes\n",
        "\n",
        "#subsetting mislabelled antoniniani\n",
        "\n",
        "anton_df = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting mislabelled denarii\n",
        "\n",
        "den_df = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 0)]\n",
        "\n",
        "#subsetting true antoniniani\n",
        "\n",
        "anton_df_true = pred_df.loc[(pred_df['predictions'] == True) & (pred_df['classes'] == 1)]\n",
        "\n",
        "#subsetting true denarii\n",
        "\n",
        "den_df_true = pred_df.loc[(pred_df['predictions'] == False) & (pred_df['classes'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO0-g356dupH"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  sp = plt.subplot(len(anton_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + anton_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl2WcAw-dupI"
      },
      "outputs": [],
      "source": [
        "#displaying mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  sp = plt.subplot(len(den_df), ncols,i+1)\n",
        "  image = load_img('tmp/coins2/test2/' + den_df.iloc[i,0])\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(image);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBTbqJdgdupJ"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled antoniniani\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(anton_df)*4)\n",
        "\n",
        "for i in range(0,len(anton_df)):\n",
        "  path = 'tmp/coins2/test2/' + anton_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "  plt.subplot(len(anton_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_l9WkNddupK"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of mislabelled denarii\n",
        "\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, len(den_df)*4)\n",
        "\n",
        "for i in range(0,len(den_df)):\n",
        "  path = 'tmp/coins2/test2/' + den_df.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=1, layer_name='conv2d_111')\n",
        "  plt.subplot(len(den_df), ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF0JG7C2dupM"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true antoniniani\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + anton_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=1, layer_name='conv2d_111')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyrrALGIdupO"
      },
      "outputs": [],
      "source": [
        "#displaying gradCAM of true negatives (=denarii)\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "for i in range(0,16):\n",
        "  path = 'tmp/coins2/test2/' + den_df_true.iloc[i,0]\n",
        "  img=tf.keras.preprocessing.image.load_img(path, target_size=(150, 150))\n",
        "  img =tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img /= 255\n",
        "  img = ([img], None)\n",
        "  explainer = GradCAM()\n",
        "  grid = explainer.explain(\n",
        "        img, model_6, class_index=0, layer_name='conv2d_111')\n",
        "  plt.subplot(nrows, ncols,i+1)\n",
        "  grid = Image.fromarray(grid)\n",
        "  plt.axis('Off')\n",
        "  plt.title(i)\n",
        "  plt.imshow(grid);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}